use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::fs;
use std::io::Write;
use std::path::{Path, PathBuf};
use std::process::{Command, Stdio};
use zip::write::FileOptions;
use zip::ZipWriter;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BuildProgress {
    pub step: String,
    pub progress: f32,
    pub message: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BuildResult {
    pub success: bool,
    pub output_path: Option<String>,
    pub error: Option<String>,
}

pub struct PluginBuilder {
    plugin_dir: PathBuf,
    plugin_id: String,
    build_dir: PathBuf,
    project_root: PathBuf,
}

impl PluginBuilder {
    pub fn new(plugin_id: &str) -> Result<Self> {
        let cwd = std::env::current_dir()?;
        let project_root = if cwd.ends_with("src-tauri") {
            cwd.parent().unwrap().to_path_buf()
        } else {
            cwd.clone()
        };

        // Check for plugin in AppData/Local/WebArcade/projects first
        let appdata_dir = dirs::data_local_dir()
            .or_else(|| dirs::data_dir())
            .expect("Could not determine data directory");

        let plugin_dir_appdata = appdata_dir.join("WebArcade").join("projects").join(plugin_id);
        let plugin_dir_root = project_root.join("src").join("plugins").join(plugin_id);

        let plugin_dir = if plugin_dir_appdata.exists() {
            plugin_dir_appdata
        } else if plugin_dir_root.exists() {
            plugin_dir_root
        } else {
            anyhow::bail!("Plugin directory does not exist: {:?} or {:?}", plugin_dir_appdata, plugin_dir_root);
        };

        let build_dir = project_root.join("dist").join("plugins").join(plugin_id);
        fs::create_dir_all(&build_dir)?;

        Ok(Self {
            plugin_dir,
            plugin_id: plugin_id.to_string(),
            build_dir,
            project_root,
        })
    }

    pub fn build(&self, progress_callback: impl Fn(BuildProgress), log_callback: impl Fn(String)) -> Result<BuildResult> {
        // Auto-detect if plugin has Rust backend (check for mod.rs or Cargo.toml)
        let has_backend = self.plugin_dir.join("mod.rs").exists()
            || self.plugin_dir.join("Cargo.toml").exists();

        // Auto-detect if plugin has frontend (check for index.jsx or index.js)
        let has_frontend = self.plugin_dir.join("index.jsx").exists()
            || self.plugin_dir.join("index.js").exists();

        progress_callback(BuildProgress {
            step: "prepare".to_string(),
            progress: 0.1,
            message: "Preparing plugin build...".to_string(),
        });

        // Clean build directory
        if self.build_dir.exists() {
            fs::remove_dir_all(&self.build_dir)?;
        }
        fs::create_dir_all(&self.build_dir)?;

        // Copy backend and compile if present
        if has_backend {
            progress_callback(BuildProgress {
                step: "backend_setup".to_string(),
                progress: 0.2,
                message: "Setting up Rust backend...".to_string(),
            });

            self.setup_backend_build()?;

            progress_callback(BuildProgress {
                step: "backend_compile".to_string(),
                progress: 0.3,
                message: "Compiling Rust backend as dynamic library...".to_string(),
            });

            self.compile_backend(&progress_callback, &log_callback)?;
        }

        // Bundle frontend
        progress_callback(BuildProgress {
            step: "frontend_bundle".to_string(),
            progress: 0.7,
            message: "Bundling frontend code...".to_string(),
        });

        self.bundle_frontend()?;

        // Create package
        progress_callback(BuildProgress {
            step: "packaging".to_string(),
            progress: 0.9,
            message: "Creating distribution package...".to_string(),
        });

        let zip_path = self.create_package()?;

        progress_callback(BuildProgress {
            step: "complete".to_string(),
            progress: 1.0,
            message: format!("Build complete: {}", zip_path),
        });

        Ok(BuildResult {
            success: true,
            output_path: Some(zip_path),
            error: None,
        })
    }


    fn setup_backend_build(&self) -> Result<()> {
        // Create a temporary build directory for Rust compilation
        let rust_build_dir = self.build_dir.join("rust_build");
        fs::create_dir_all(&rust_build_dir)?;

        // Copy all plugin Rust source files
        self.copy_rust_files(&self.plugin_dir, &rust_build_dir)?;

        // Check if plugin has its own Cargo.toml
        let plugin_cargo_toml = self.plugin_dir.join("Cargo.toml");
        let api_path = self.project_root.join("src-tauri").join("api");
        let api_path_str = api_path.to_string_lossy().replace("\\", "/");

        let cargo_toml = if plugin_cargo_toml.exists() {
            // Read existing Cargo.toml and update api path to absolute
            let mut content = fs::read_to_string(&plugin_cargo_toml)?;

            // Check if api is already present
            let re = regex::Regex::new(r#"api\s*=\s*\{[^}]*path\s*=\s*"[^"]*"[^}]*\}"#).unwrap();

            content = if re.is_match(&content) {
                // Replace existing api path
                re.replace(&content, format!("api = {{ path = \"{}\" }}", api_path_str)).to_string()
            } else {
                // Inject api if not present
                // Find [dependencies] section and add it there
                let deps_re = regex::Regex::new(r"(?m)^\[dependencies\]\s*$").unwrap();
                if let Some(mat) = deps_re.find(&content) {
                    let insert_pos = mat.end();
                    let mut new_content = content.clone();
                    new_content.insert_str(insert_pos, &format!("\napi = {{ path = \"{}\" }}", api_path_str));
                    new_content
                } else {
                    // No [dependencies] section found, add it before [profile.release] or at the end
                    let profile_re = regex::Regex::new(r"(?m)^\[profile\.release\]").unwrap();
                    if let Some(mat) = profile_re.find(&content) {
                        let insert_pos = mat.start();
                        let mut new_content = content.clone();
                        new_content.insert_str(insert_pos, &format!("[dependencies]\napi = {{ path = \"{}\" }}\n\n", api_path_str));
                        new_content
                    } else {
                        // Add at the end
                        format!("{}\n[dependencies]\napi = {{ path = \"{}\" }}\n", content, api_path_str)
                    }
                }
            };

            // Ensure [lib] section exists with correct configuration
            // Remove any existing [lib] section first (match from [lib] to next section or end of file)
            let lib_section_re = regex::Regex::new(r"(?m)\n?\[lib\][^\[]*").unwrap();
            content = lib_section_re.replace(&content, "").to_string();

            // Find [package] section and insert [lib] after it
            // Match [package] and everything until the next section
            let package_re = regex::Regex::new(r"(?m)(\[package\][^\[]+)").unwrap();
            if let Some(mat) = package_re.find(&content) {
                let insert_pos = mat.end();
                content.insert_str(insert_pos, "\n[lib]\ncrate-type = [\"cdylib\"]\npath = \"lib.rs\"\n");
            }

            content
        } else {
            // Create default Cargo.toml
            format!(
                r#"[package]
name = "{}"
version = "1.0.0"
edition = "2021"

[dependencies]

[profile.release]
opt-level = "z"
lto = true
codegen-units = 1
strip = true
"#,
                self.plugin_id
            )
        };

        fs::write(rust_build_dir.join("Cargo.toml"), cargo_toml)?;

        // Create .cargo/config.toml to allow undefined symbols (they'll be resolved at runtime)
        let cargo_config_dir = rust_build_dir.join(".cargo");
        fs::create_dir_all(&cargo_config_dir)?;

        let cargo_config = r#"[target.x86_64-pc-windows-msvc]
rustflags = ["-C", "link-args=/FORCE:UNRESOLVED"]

[target.x86_64-unknown-linux-gnu]
rustflags = ["-C", "link-args=-Wl,--allow-shlib-undefined"]

[target.x86_64-apple-darwin]
rustflags = ["-C", "link-args=-undefined dynamic_lookup"]

[target.aarch64-apple-darwin]
rustflags = ["-C", "link-args=-undefined dynamic_lookup"]
"#;
        fs::write(cargo_config_dir.join("config.toml"), cargo_config)?;

        // Create lib.rs that includes core and the plugin
        self.create_lib_rs(&rust_build_dir)?;

        Ok(())
    }

    fn create_lib_rs(&self, rust_build_dir: &Path) -> Result<()> {
        // Get plugin struct name (e.g., "MyPlugin" from plugin dir name)
        let plugin_struct = self.get_plugin_struct_name();

        // Extract handler functions from router.rs with their signatures
        let handlers = self.extract_handler_signatures()?;

        // Generate handler wrapper functions
        let handler_wrappers = handlers.iter().map(|(handler_name, params)| {
            // Determine what arguments to pass based on the parameters
            let (handler_args, needs_request) = if params.is_empty() {
                (String::new(), false)
            } else if params.len() == 1 && params[0].1.contains("HttpRequest") {
                // Handler takes only HttpRequest
                ("dummy_req".to_string(), true)
            } else if params.len() == 2 && params[0].1.contains("HttpRequest") && params[1].1.contains("String") {
                // Handler takes HttpRequest and path String
                ("dummy_req, String::new()".to_string(), true)
            } else {
                // Unknown parameter pattern - try to pass dummy values
                let has_req = params.iter().any(|(_, ty)| ty.contains("HttpRequest"));
                let args = params.iter().map(|(_, ty)| {
                    if ty.contains("HttpRequest") {
                        "dummy_req"
                    } else if ty.contains("String") {
                        "String::new()"
                    } else {
                        "Default::default()"
                    }
                }).collect::<Vec<_>>().join(", ");
                (args, has_req)
            };

            // Create dummy request if needed - we need to transmute an empty body to Incoming
            // This is safe because we're just creating a request that will be immediately consumed
            let create_dummy_req = if needs_request {
                r#"
            // Create a dummy HTTP request with an empty body
            // SAFETY: We're creating an empty request for handlers that will ignore the body
            use api::http_body_util::Empty;
            use api::hyper::body::Bytes;
            let empty_body = Empty::<Bytes>::new();

            // We need to convert Empty to Incoming, which is tricky
            // For now, we'll use an unsafe transmute since the handler shouldn't read the body
            let dummy_req: api::hyper::Request<api::hyper::body::Incoming> = unsafe {
                std::mem::transmute(
                    api::hyper::Request::builder()
                        .method("GET")
                        .uri("/")
                        .body(empty_body)
                        .unwrap()
                )
            };"#
            } else {
                ""
            };

            format!("
#[no_mangle]
pub extern \"C\" fn {}() -> *const u8 {{
    use std::panic;
    use std::ffi::CString;

    let result = panic::catch_unwind(|| {{
        // Use the shared runtime instead of creating a new one
        get_runtime().block_on(async {{
            use api::http_body_util::BodyExt;
{}
            // Call the handler and get the HttpResponse
            let response = plugin_mod::router::{}({}).await;

            // Extract the body bytes from the response
            let (_parts, body) = response.into_parts();
            let body_bytes = body.collect().await.unwrap().to_bytes();
            let body_str = String::from_utf8(body_bytes.to_vec()).unwrap();

            body_str
        }})
    }});

    match result {{
        Ok(json_string) => {{
            // Convert to CString to ensure null-termination for C FFI
            let c_string = CString::new(json_string).unwrap();
            Box::leak(Box::new(c_string)).as_ptr() as *const u8
        }}
        Err(_) => {{
            let error = CString::new(\"{{\\\"error\\\": \\\"Handler panicked\\\"}}\").unwrap();
            Box::leak(Box::new(error)).as_ptr() as *const u8
        }}
    }}
}}
", handler_name, create_dummy_req, handler_name, handler_args)
        }).collect::<Vec<_>>().join("\n");

        let lib_content = format!(r#"// Auto-generated plugin library
// This file uses the api crate to provide a clean plugin interface

// Include plugin modules
pub mod plugin_mod;

// Re-export plugin
pub use plugin_mod::*;
use api::tokio;
use std::sync::{{Arc, OnceLock}};

// Shared runtime for all handler calls to avoid creating multiple runtimes
static RUNTIME: OnceLock<Arc<tokio::runtime::Runtime>> = OnceLock::new();

fn get_runtime() -> &'static Arc<tokio::runtime::Runtime> {{
    RUNTIME.get_or_init(|| {{
        Arc::new(
            tokio::runtime::Builder::new_multi_thread()
                .enable_all()
                .worker_threads(2)
                .build()
                .expect("Failed to create tokio runtime")
        )
    }})
}}

// Export plugin lifecycle functions for dynamic loading
// Note: These are no-ops since we use manifest-based routing
#[no_mangle]
pub extern "C" fn plugin_init(_ffi_ctx: *const ()) -> i32 {{
    // Routes are registered from manifest, so init is a no-op
    0
}}

#[no_mangle]
pub extern "C" fn plugin_start(_ffi_ctx: *const ()) -> i32 {{
    // Routes are registered from manifest, so start is a no-op
    0
}}

#[no_mangle]
pub extern "C" fn plugin_stop() -> i32 {{
    // Stop is a no-op for manifest-based plugins
    0
}}

#[no_mangle]
pub extern "C" fn plugin_metadata() -> *const u8 {{
    use api::{{Plugin, serde_json}};
    let plugin = plugin_mod::{};
    let metadata = plugin.metadata();
    let json = serde_json::to_string(&metadata).unwrap_or_default();
    Box::leak(Box::new(json)).as_ptr() as *const u8
}}

// Auto-generated handler wrappers
{}
"#, plugin_struct, handler_wrappers);

        fs::write(rust_build_dir.join("lib.rs"), lib_content)?;

        Ok(())
    }

    fn extract_handlers(&self) -> Result<Vec<String>> {
        let router_path = self.plugin_dir.join("router.rs");
        if !router_path.exists() {
            return Ok(Vec::new());
        }

        let content = fs::read_to_string(&router_path)?;
        let mut handlers = Vec::new();

        // Look for route! macro usages to extract handler names
        // Pattern: route!(router, METHOD "/path" => handler_name);
        // Pattern: route!(router, METHOD "/path", path => handler_name);
        let re = regex::Regex::new(r"route!\s*\([^,]+,\s*\w+\s+[^=]+(?:,\s*path\s*)?=>\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*\)").unwrap();

        for cap in re.captures_iter(&content) {
            if let Some(handler_name) = cap.get(1) {
                handlers.push(handler_name.as_str().to_string());
            }
        }

        Ok(handlers)
    }

    fn extract_handler_signatures(&self) -> Result<Vec<(String, Vec<(String, String)>)>> {
        let router_path = self.plugin_dir.join("router.rs");
        if !router_path.exists() {
            return Ok(Vec::new());
        }

        let content = fs::read_to_string(&router_path)?;
        let mut handlers = Vec::new();

        // First get handler names from route! macros
        let handler_names = self.extract_handlers()?;

        // For each handler, find its function signature
        for handler_name in handler_names {
            // Match: pub async fn handler_name(param1: Type1, param2: Type2) -> HttpResponse
            let pattern = format!(
                r"(?:pub\s+)?async\s+fn\s+{}\s*\(([^)]*)\)\s*->\s*HttpResponse",
                regex::escape(&handler_name)
            );
            let re = regex::Regex::new(&pattern).unwrap();

            if let Some(cap) = re.captures(&content) {
                if let Some(params_str) = cap.get(1) {
                    let params_str = params_str.as_str().trim();
                    let mut params = Vec::new();

                    if !params_str.is_empty() {
                        // Split by comma and parse each parameter
                        for param in params_str.split(',') {
                            let param = param.trim();
                            if let Some(colon_pos) = param.find(':') {
                                let name = param[..colon_pos].trim().to_string();
                                let ty = param[colon_pos + 1..].trim().to_string();
                                params.push((name, ty));
                            }
                        }
                    }

                    handlers.push((handler_name.clone(), params));
                } else {
                    // No parameters
                    handlers.push((handler_name.clone(), Vec::new()));
                }
            } else {
                // Couldn't find signature, assume no parameters
                handlers.push((handler_name.clone(), Vec::new()));
            }
        }

        Ok(handlers)
    }

    fn get_plugin_struct_name(&self) -> String {
        // Convert plugin_id to PascalCase and add "Plugin" suffix
        let parts: Vec<&str> = self.plugin_id.split('_').collect();
        let mut name = String::new();
        for part in parts {
            let mut chars = part.chars();
            if let Some(first) = chars.next() {
                name.push(first.to_uppercase().next().unwrap());
                name.push_str(chars.as_str());
            }
        }
        name.push_str("Plugin");
        name
    }

    fn copy_rust_files(&self, src: &Path, dst: &Path) -> Result<()> {
        // Create plugin_mod directory to hold the plugin files
        let plugin_mod_dir = dst.join("plugin_mod");
        fs::create_dir_all(&plugin_mod_dir)?;

        for entry in fs::read_dir(src)? {
            let entry = entry?;
            let path = entry.path();
            let file_name = entry.file_name();
            let file_name_str = file_name.to_string_lossy();

            if path.is_file() {
                if let Some(ext) = path.extension() {
                    if ext == "rs" {
                        let dest_path = plugin_mod_dir.join(&file_name);

                        let content = fs::read_to_string(&path)?;
                        let modified_content = if file_name_str == "mod.rs" {
                            // Make the router module public
                            content.replace("mod router;", "pub mod router;")
                        } else if file_name_str == "router.rs" {
                            // Make handler functions public (if not already)
                            // Pattern: async fn handler_name(...) -> HttpResponse
                            let re = regex::Regex::new(r"(?m)^async fn ([a-zA-Z_][a-zA-Z0-9_]*)\(([^)]*)\) -> HttpResponse").unwrap();
                            re.replace_all(&content, "pub async fn $1($2) -> HttpResponse").to_string()
                        } else {
                            content
                        };

                        fs::write(&dest_path, modified_content)?;
                    }
                }
            }
        }

        Ok(())
    }

    fn compile_backend(&self, progress_callback: &impl Fn(BuildProgress), log_callback: &impl Fn(String)) -> Result<()> {
        let rust_build_dir = self.build_dir.join("rust_build");

        log::info!("[Developer] Compiling {} as cdylib...", self.plugin_id);
        log_callback(format!("Compiling {} as cdylib...", self.plugin_id));

        // Build for current platform
        let mut cmd = Command::new("cargo");
        cmd.current_dir(&rust_build_dir)
            .args(&["build", "--release", "--lib"])
            .stdout(Stdio::piped())
            .stderr(Stdio::piped());

        log_callback("Running: cargo build --release --lib".to_string());

        let mut child = cmd.spawn().context("Failed to spawn cargo build")?;

        // Read both stdout and stderr concurrently using threads and channels
        use std::io::BufRead;
        use std::sync::mpsc;

        let stdout = child.stdout.take();
        let stderr = child.stderr.take();

        let (tx, rx) = mpsc::channel::<String>();

        let mut handles = vec![];

        // Spawn thread for stdout
        if let Some(stdout) = stdout {
            let tx = tx.clone();
            let handle = std::thread::spawn(move || {
                let reader = std::io::BufReader::new(stdout);
                for line in reader.lines() {
                    if let Ok(line) = line {
                        let _ = tx.send(line);
                    }
                }
            });
            handles.push(handle);
        }

        // Spawn thread for stderr
        if let Some(stderr) = stderr {
            let tx = tx.clone();
            let handle = std::thread::spawn(move || {
                let reader = std::io::BufReader::new(stderr);
                for line in reader.lines() {
                    if let Ok(line) = line {
                        let _ = tx.send(line);
                    }
                }
            });
            handles.push(handle);
        }

        // Drop the original sender so the channel closes when threads are done
        drop(tx);

        // Receive and log messages from both streams
        for msg in rx {
            log_callback(msg);
        }

        // Wait for both threads to finish
        for handle in handles {
            let _ = handle.join();
        }

        let status = child.wait().context("Failed to wait for cargo build")?;

        if !status.success() {
            log::error!("[Developer] Cargo build failed");
            log_callback("Cargo build failed!".to_string());
            anyhow::bail!("Cargo build failed");
        }

        log_callback("Rust compilation successful!".to_string());

        progress_callback(BuildProgress {
            step: "backend_compile".to_string(),
            progress: 0.6,
            message: "Rust compilation successful".to_string(),
        });

        // Copy compiled binaries to build output
        self.copy_compiled_binaries(&rust_build_dir)?;

        Ok(())
    }

    fn copy_compiled_binaries(&self, rust_build_dir: &Path) -> Result<()> {
        let target_dir = rust_build_dir.join("target").join("release");

        // Determine library name based on platform
        let lib_patterns = if cfg!(target_os = "windows") {
            vec![format!("{}.dll", self.plugin_id)]
        } else if cfg!(target_os = "macos") {
            vec![format!("lib{}.dylib", self.plugin_id)]
        } else {
            vec![format!("lib{}.so", self.plugin_id)]
        };

        // Find and copy the compiled library directly to build_dir root
        for pattern in lib_patterns {
            let src_path = target_dir.join(&pattern);
            if src_path.exists() {
                let dest_path = self.build_dir.join(&pattern);
                fs::copy(&src_path, &dest_path)?;

                log::info!("[Developer] Copied binary to root: {}", pattern);
                return Ok(());
            }
        }

        anyhow::bail!("Could not find compiled library in {:?}", target_dir);
    }

    fn bundle_frontend(&self) -> Result<()> {
        // Check if plugin has frontend files
        let has_frontend = self.plugin_dir.join("index.jsx").exists()
            || self.plugin_dir.join("index.js").exists();

        if !has_frontend {
            log::info!("[Developer] No frontend files found, skipping frontend bundling");
            return Ok(());
        }

        // Install npm dependencies if package.json has dependencies
        self.install_npm_dependencies()?;

        // Use Node.js bundler to bundle frontend code
        log::info!("[Developer] Bundling frontend with RSpack...");

        let bundler_script = self.project_root.join("scripts/build_plugin.js");
        let plugin_dir_str = self.plugin_dir.to_string_lossy();
        let build_dir_str = self.build_dir.to_string_lossy();

        // Run the Node.js bundler (try bun first, then node)
        let output = if Command::new("bun").arg("--version").output().is_ok() {
            Command::new("bun")
                .arg("run")
                .arg(bundler_script)
                .arg(&*plugin_dir_str)
                .arg(&*build_dir_str)
                .output()
                .context("Failed to execute frontend bundler with bun")?
        } else {
            Command::new("node")
                .arg(bundler_script)
                .arg(&*plugin_dir_str)
                .arg(&*build_dir_str)
                .output()
                .context("Failed to execute frontend bundler with node")?
        };

        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            let stdout = String::from_utf8_lossy(&output.stdout);
            log::error!("[Developer] Frontend bundling failed:");
            log::error!("    STDOUT:\n{}", stdout);
            log::error!("    STDERR:\n{}", stderr);
            anyhow::bail!("Frontend bundling failed: {}", stderr);
        }

        let stdout = String::from_utf8_lossy(&output.stdout);
        log::info!("[Developer] Frontend bundling output:\n{}", stdout);

        Ok(())
    }

    fn install_npm_dependencies(&self) -> Result<()> {
        let package_json_path = self.plugin_dir.join("package.json");

        // Check if package.json exists and has dependencies
        if !package_json_path.exists() {
            return Ok(());
        }

        let content = fs::read_to_string(&package_json_path)?;
        let json: serde_json::Value = serde_json::from_str(&content)?;

        // Check if there are any dependencies or devDependencies
        let has_deps = json.get("dependencies").and_then(|d| d.as_object()).map(|o| !o.is_empty()).unwrap_or(false);
        let has_dev_deps = json.get("devDependencies").and_then(|d| d.as_object()).map(|o| !o.is_empty()).unwrap_or(false);

        if !has_deps && !has_dev_deps {
            log::info!("[Developer] No npm dependencies to install");
            return Ok(());
        }

        log::info!("[Developer] Installing npm dependencies...");

        // Try bun first (faster), then npm
        let install_result = if Command::new("bun").arg("--version").output().is_ok() {
            log::info!("[Developer] Using bun to install dependencies");
            Command::new("bun")
                .arg("install")
                .current_dir(&self.plugin_dir)
                .output()
        } else {
            log::info!("[Developer] Using npm to install dependencies");
            Command::new("npm")
                .arg("install")
                .current_dir(&self.plugin_dir)
                .output()
        };

        match install_result {
            Ok(output) => {
                if !output.status.success() {
                    let stderr = String::from_utf8_lossy(&output.stderr);
                    log::warn!("[Developer] Dependency installation had issues: {}", stderr);
                    // Don't fail the build, just warn - bundler might still work
                } else {
                    log::info!("[Developer] Dependencies installed successfully");
                }
            }
            Err(e) => {
                log::warn!("[Developer] Could not install dependencies: {}", e);
                // Don't fail the build - user might have dependencies pre-installed
            }
        }

        Ok(())
    }

    fn copy_dir_recursive(&self, src: &Path, dst: &Path) -> Result<()> {
        fs::create_dir_all(dst)?;

        for entry in fs::read_dir(src)? {
            let entry = entry?;
            let path = entry.path();
            let file_name = entry.file_name();
            let dst_path = dst.join(&file_name);

            if path.is_dir() {
                self.copy_dir_recursive(&path, &dst_path)?;
            } else {
                fs::copy(&path, &dst_path)?;
            }
        }

        Ok(())
    }

    fn create_package(&self) -> Result<String> {
        let cwd = std::env::current_dir()?;
        let dist_root = if cwd.ends_with("src-tauri") {
            cwd.parent().unwrap().join("dist")
        } else {
            cwd.join("dist")
        };

        fs::create_dir_all(&dist_root)?;

        let zip_path = dist_root.join(format!("{}.zip", self.plugin_id));
        let zip_file = fs::File::create(&zip_path)?;
        let mut zip = ZipWriter::new(zip_file);
        let options = FileOptions::default()
            .compression_method(zip::CompressionMethod::Deflated);

        // Add all files from build_dir root (flat structure)
        for entry in fs::read_dir(&self.build_dir)? {
            let entry = entry?;
            let path = entry.path();
            let file_name = entry.file_name();
            let file_name_str = file_name.to_string_lossy();

            // Skip directories (like rust_build, src)
            if path.is_dir() {
                continue;
            }

            // Add file to zip root
            zip.start_file(file_name_str.as_ref(), options)?;
            let content = fs::read(&path)?;
            zip.write_all(&content)?;
        }

        // Add package.json (updated with webarcade config)
        let package_json = self.create_package_json()?;
        zip.start_file("package.json", options)?;
        zip.write_all(package_json.as_bytes())?;

        // Add README - detect backend from built files
        let has_dll = self.build_dir.join(format!("{}.dll", self.plugin_id)).exists();
        let has_so = self.build_dir.join(format!("lib{}.so", self.plugin_id)).exists();
        let has_dylib = self.build_dir.join(format!("lib{}.dylib", self.plugin_id)).exists();
        let has_backend_file = has_dll || has_so || has_dylib;

        let readme = format!(
            r#"# {} Plugin

WebArcade Plugin Package

## Installation

Drag and drop this .zip file anywhere in the WebArcade window to install.

## Contents

- Frontend: {}
- Backend: {}
- Platform: {}

## Plugin Structure

All files are in the root directory for simplicity:
- package.json - Plugin metadata, routes, and dependencies
- plugin.js - Frontend code (if present)
- *.dll / lib*.so / lib*.dylib - Native binary (if present)

## Note

This plugin was built on {} and may include platform-specific binaries.
For other platforms, you may need to rebuild from source.
"#,
            self.plugin_id,
            if self.build_dir.join("plugin.js").exists() { "Included" } else { "None" },
            if has_backend_file { "Included" } else { "None" },
            if cfg!(target_os = "windows") {
                "Windows"
            } else if cfg!(target_os = "macos") {
                "macOS"
            } else {
                "Linux"
            },
            chrono::Utc::now().format("%Y-%m-%d %H:%M:%S UTC")
        );

        zip.start_file("README.md", options)?;
        zip.write_all(readme.as_bytes())?;

        zip.finish()?;

        Ok(zip_path.to_string_lossy().to_string())
    }

    fn create_package_json(&self) -> Result<String> {
        let package_json_path = self.plugin_dir.join("package.json");

        // Read existing package.json or create a new one
        let mut package_json = if package_json_path.exists() {
            let content = fs::read_to_string(package_json_path)?;
            serde_json::from_str::<serde_json::Value>(&content)?
        } else {
            serde_json::json!({
                "name": self.plugin_id,
                "version": "1.0.0",
                "description": "",
                "author": "Unknown"
            })
        };

        // Extract routes from router.rs or use existing routes from package.json
        let routes = if let Some(existing_routes) = package_json.get("webarcade")
            .and_then(|wa| wa.get("routes"))
            .and_then(|r| r.as_array()) {
            existing_routes.clone()
        } else {
            self.extract_routes()?
        };

        // Create or update webarcade section - only store id and routes
        // has_backend and has_frontend are auto-detected at runtime
        let webarcade_config = serde_json::json!({
            "id": package_json.get("webarcade")
                .and_then(|wa| wa.get("id"))
                .and_then(|id| id.as_str())
                .unwrap_or(&self.plugin_id),
            "routes": routes
        });

        // Merge webarcade config into package.json
        package_json["webarcade"] = webarcade_config;

        Ok(serde_json::to_string_pretty(&package_json)?)
    }

    fn extract_routes(&self) -> Result<Vec<serde_json::Value>> {
        let router_path = self.plugin_dir.join("router.rs");
        if !router_path.exists() {
            return Ok(Vec::new());
        }

        let content = fs::read_to_string(&router_path)?;
        let mut routes = Vec::new();

        // Pattern: route!(router, METHOD "/path" => handler_name);
        // Pattern: route!(router, METHOD "/path", path => handler_name);
        let re = regex::Regex::new(r#"route!\s*\([^,]+,\s*(\w+)\s+"([^"]+)"(?:,\s*path\s*)?=>\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*\)"#).unwrap();

        for cap in re.captures_iter(&content) {
            if let (Some(method), Some(path), Some(handler)) = (cap.get(1), cap.get(2), cap.get(3)) {
                routes.push(serde_json::json!({
                    "method": method.as_str(),
                    "path": path.as_str(),
                    "handler": handler.as_str(),
                }));
            }
        }

        Ok(routes)
    }

}
